* variables
* struct types
- alignment, padding
  - every 2 byte value must fall on a 2 byte boundry
- define structs with higher and similiar types first
- padding for struct is the padding of the highest size member
* Pointers
- in go it is always pass by value
- sharing a value across program boundries
- each goroutine gets a stack of size 2k
  - each stack can grow to a bigger size
  - pointers cannot be shared across goroutine stack
  - stack memory cannot be shared among go routine
- every function is given stackframe
  - size of each stackframe is known at compile time
* constants
- typed ~const x int = 9~
- untyped *kind* ~cons x = 9~
  - precision can be upto 256 bits
- type promotes over kind
- only exist at compile time
* Functions
- return 2 when second is error
- factory functions
- farther the variable name from usage, longer it should be
- blank variable
- compact if syntax
~if _, err := getUser(); err != nil {~
  ~fmt.println(err)~
  ~return~
~}~
* Data Structures
- write code that is symphatetic with cache system
* interfaces
- if you implement an interface using a pointer receiver, then only pointers of that type implement the interface. If you implement an interface using a value receiver, then both values and pointers of that type implement the interface.
* type embedding
- take existing types and both extend and change their behavior.
- It works by taking an existing type and declaring that type within the declaration of a new struct type.
- The type that is embedded is then called an inner type of the new outer type.
* concurrency
- /Concurrency is a property of the code; parallelism is a property of the running program./
- *Communicating Sequential Processes*
- /Do not communicate by sharing memory. Instead, share memory by communicating./
- /aim for simplicity, use channels when possible, and treat goroutines like a free resource./
** goroutine
- a goroutine is a coroutine (concurrent subroutine) that are nonpreemptive
- When a function is created as a goroutine, it’s treated as an independent unit of work that gets scheduled and then executed on an available logical processor
- /M:N scheduler/
  - m green threads --> n os threads
- *fork-join model*
- go runtime scheduler
  - manages goroutines
  - sits on top of the operating system
  - binding operating system’s threads to logical processors which, in turn, execute goroutines.
  - Each logical processor is individually bound to a single operating system thread.
  - default is to allocate a logical processor for every physical processor that’s available.
- CSP *communicating sequential processes*
  - message-passing model that works by communicating data between goroutines
- Blocking calls
  - Thread and goroutine is detached from the logical processor. Thread continue to wait for the syscall to return.
  - The logical processor is attached to a new thread.
- IO call
  - the goroutine is detached from the logical processor and moved to the runtime integrated network poller.
  - once poller indicates read/write op is ready, goroutine is assigned back to the logical processor.
*** pass a copy
#+begin_src go 
  var wg sync.WaitGroup
  for _, salutation := range []string{"hello", "greetings", "good day"} {
          wg.Add(1)
          go func(salutation string) {
                  defer wg.Done()
                  fmt.Println(salutation)
          }(salutation)
  }
  wg.Wait()
#+end_src
** sync
- *waitGroup*
- *Mutex & RWMutex*
  - call ~Unlock~ with defer statement.
  - ensure it runs even for panic
- *cond*
  - one or more goroutine waits for a condition
  - ~.Signal~ for one goroutine waiting
  - ~.Broadcast~ for multiple goroutines in ~FIFO~ order
  - call ~.Wait~ automatically unlocks
  - exiting ~.Wait~ automatically locks
- *Once*
- *pool*
  - object pool design pattern is best used either when you have concurrent processes that require objects, but dispose of them very rapidly after instantiation, or when construction of these objects could negatively impact memory.
** channels
- unbuffered channel
  - is a channel with no capacity to hold any value before it’s received
  - sending and receiving goroutine to be ready at the same instant before any send or receive operation can complete.
- synchronize goroutines as they send and receive the resources they need to share between each other.
- When a resource needs to be shared between goroutines, channels act as a conduit between the goroutines and provide a mechanism that guarantees a synchronous exchange.
- When a channel is closed, goroutines can still perform receives on the channel but can no longer send on the channel
- *range*
  - read all values until channel is closed
- *close*
  - notify multiple goroutines
  - closed channel can be read infinite number of times
- *select*
  - The select statement lets a goroutine wait on multiple communication operations.
  - A select blocks until one of its cases can run, then it executes that case.
  - It chooses one at random if multiple are ready.
  - glue that bind channels together
  - compose channels
  - /all channel reads and writes are considered simultaneously/
  - /perform a pseudo-random uniform selection over the set of case statements/
** patterns
- *confinement*
  - lexical confinement : /using lexical scope to expose only the correct data and concurrency primitives for multiple concurrent processes to use./
  - adhoc confinement   :
- *for-select-loop*
  - /If a goroutine is responsible for creating a goroutine, it is also responsible for ensuring it can stop the goroutine./
- *or-channel*
- *error handling*
  - couple error with other outcomes
  - consider error as first class citizens
- *pipelines*
  - /batch processing/ : all values in the container (e.g. list)
  - /sream processing/ : one value at a time
- *queue*
  - introducing a queue isn’t that the runtime of one of stages has been reduced, but rather that the time it’s in a blocking state is reduced.
  - decouple stages so that the runtime of one stage has no impact on the runtime of another.
  - if queuing can increase the overall performance of the system
    - If batching requests in a stage saves time
    - If delays in a stage produce a feedback loop into the system.
      - used for negative feedback loop or death spiral
      - add queue at the entrance of the pipeline
*** Little's law
#+begin_src 
L = avg num of units in system

r = avg arrival rate of units

w = avg time a unit spends in system
#+end_src
*** context package
- A goroutine’s parent may want to cancel it.
- A goroutine may want to cancel its children.
- Any blocking operations within a goroutine need to be preemptable so that it may be canceled.
** at-scale
- *heartbeats*
  - signal life to an observer
  - 2 types
    1. occur at regular interval
    2. occur at the beginning of a unit of work

